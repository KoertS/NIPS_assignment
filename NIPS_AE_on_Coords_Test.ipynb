{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NIPS_AE_on_Coords_Test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7J73054mCaJ",
        "outputId": "09935d4a-b7ed-4000-89db-ff8a8d24a142"
      },
      "source": [
        "!pip install mxnet-cu101"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet-cu101 in /usr/local/lib/python3.6/dist-packages (1.7.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101) (1.18.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n70DCLNpmGgk"
      },
      "source": [
        "import os\n",
        "\n",
        "import mxnet as mx\n",
        "import numpy as np\n",
        "import torch\n",
        "from mxnet import gluon\n",
        "from torchvision.utils import save_image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "SqY1Qb_Cs-k9",
        "outputId": "0b676180-225c-4508-85a0-a2e629e2669f"
      },
      "source": [
        "# sample coords contains a sample of coordinates for red and blue\n",
        "df = pd.read_csv('sample_coords.csv', header=None)\n",
        "df.columns=['x1','y1', 'x2','y2']\n",
        "print(df.shape)\n",
        "x_bounds = [min(min(df.x1), min(df.x2)) , max(max(df.x1), max(df.x2))]\n",
        "y_bounds = [min(min(df.y1), min(df.y2)) , max(max(df.y1), max(df.y2))]\n",
        "print(x_bounds)\n",
        "print(y_bounds)\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2307, 4)\n",
            "[-120.0, 62.0]\n",
            "[-120.0, 118.5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>y1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-57.714286</td>\n",
              "      <td>80.142857</td>\n",
              "      <td>-62.125000</td>\n",
              "      <td>-83.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-59.333333</td>\n",
              "      <td>59.833333</td>\n",
              "      <td>-63.250000</td>\n",
              "      <td>-62.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-66.200000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>-65.100000</td>\n",
              "      <td>-46.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-59.333333</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>-64.142857</td>\n",
              "      <td>-29.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-60.833333</td>\n",
              "      <td>14.166667</td>\n",
              "      <td>-59.444444</td>\n",
              "      <td>-13.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          x1         y1         x2         y2\n",
              "0 -57.714286  80.142857 -62.125000 -83.500000\n",
              "1 -59.333333  59.833333 -63.250000 -62.125000\n",
              "2 -66.200000  42.000000 -65.100000 -46.200000\n",
              "3 -59.333333  31.000000 -64.142857 -29.428571\n",
              "4 -60.833333  14.166667 -59.444444 -13.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "G-E1SPA1ur3x",
        "outputId": "b6f6a53b-c4c0-4da6-bf22-98c3f06344cd"
      },
      "source": [
        "def plot_coords(real_coords, memory_coords, save_as=None):  \n",
        "  plt.figure()\n",
        "  x = [real_coords[0], real_coords[2]]\n",
        "  y = [real_coords[1], real_coords[3]]\n",
        "  plt.scatter(x, y, label='real')\n",
        "  x = [memory_coords[0], memory_coords[2]]\n",
        "  y = [memory_coords[1], memory_coords[3]]\n",
        "  plt.scatter(x, y, label='memory', marker='x')\n",
        "\n",
        "  plt.xlim(x_bounds)\n",
        "  plt.ylim(y_bounds)\n",
        "  plt.legend()\n",
        "  \n",
        "  if save_as:\n",
        "    plt.savefig(save_as)\n",
        "    plt.close()\n",
        "# test plot function\n",
        "plot_coords(df.iloc[1], df.iloc[0])"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YAvrirumhqR"
      },
      "source": [
        "class autoencoder(gluon.Block):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        with self.name_scope():\n",
        "            self.encoder = gluon.nn.Sequential('encoder_')\n",
        "            with self.encoder.name_scope():\n",
        "                self.encoder.add(gluon.nn.Dense(4, in_units = 4,  activation='relu'))\n",
        "                self.encoder.add(gluon.nn.Dense(2))\n",
        "\n",
        "            self.decoder = gluon.nn.Sequential('decoder_')\n",
        "            with self.decoder.name_scope():\n",
        "                self.decoder.add(gluon.nn.Dense(2, in_units =2, activation='relu'))\n",
        "                self.decoder.add(gluon.nn.Dense(4))\n",
        "\n",
        "    def encode(self, x):\n",
        "      return self.encoder(x)\n",
        "\n",
        "    def decode(self, x):\n",
        "      return self.decoder(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvoWmbDOQuzt"
      },
      "source": [
        "if not os.path.exists('./mlp_img'):\n",
        "    os.mkdir('./mlp_img')"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p51W0AILVZM"
      },
      "source": [
        "num_epochs = 200\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "ctx = mx.cpu()"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z77pdheJMtDm"
      },
      "source": [
        "# convert dataframe to gluon dataset\n",
        "arr = df.to_numpy(dtype=np.float32)\n",
        "dataset = mx.gluon.data.dataset.ArrayDataset(arr)\n",
        "\n",
        "dataloader = mx.gluon.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HdcjgHvmnLx",
        "outputId": "43d36388-29cf-400f-a3c7-dc32c6da4be0"
      },
      "source": [
        "model = autoencoder()\n",
        "model.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
        "criterion = gluon.loss.L2Loss()\n",
        "\n",
        "optimizer = gluon.Trainer(model.collect_params(), 'adam',\n",
        "                          {'learning_rate': learning_rate,\n",
        "                           'wd': 1e-5})\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    n_total = 0.0\n",
        "    for data in dataloader:\n",
        "        with mx.autograd.record():\n",
        "            output = model(data)\n",
        "            loss = criterion(output, data)\n",
        "        loss.backward()\n",
        "        optimizer.step(batch_size)\n",
        "        running_loss += mx.nd.sum(loss).asscalar()\n",
        "        n_total += batch_size\n",
        "    # ===================log========================\n",
        "    print('epoch [{}/{}], loss:{:.4f}'\n",
        "          .format(epoch + 1, num_epochs, running_loss / n_total))\n",
        "    if epoch % 25 == 0:\n",
        "      #data\n",
        "      real = data.asnumpy().flatten()\n",
        "      memory = output.asnumpy().flatten()\n",
        "      plot_coords(real, memory, './mlp_img/{}_autoencoder.png'.format(epoch))\n",
        "model.save_parameters('./simple_autoencoder.params')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch [1/200], loss:2069.8706\n",
            "epoch [2/200], loss:2061.2430\n",
            "epoch [3/200], loss:2045.3629\n",
            "epoch [4/200], loss:2016.0634\n",
            "epoch [5/200], loss:1971.0909\n",
            "epoch [6/200], loss:1909.2814\n",
            "epoch [7/200], loss:1830.4764\n",
            "epoch [8/200], loss:1736.1517\n",
            "epoch [9/200], loss:1629.0153\n",
            "epoch [10/200], loss:1512.8638\n",
            "epoch [11/200], loss:1393.6549\n",
            "epoch [12/200], loss:1276.9227\n",
            "epoch [13/200], loss:1161.8209\n",
            "epoch [14/200], loss:1051.0209\n",
            "epoch [15/200], loss:949.7643\n",
            "epoch [16/200], loss:860.7399\n",
            "epoch [17/200], loss:786.4742\n",
            "epoch [18/200], loss:728.0319\n",
            "epoch [19/200], loss:683.7532\n",
            "epoch [20/200], loss:648.2894\n",
            "epoch [21/200], loss:618.6599\n",
            "epoch [22/200], loss:591.9107\n",
            "epoch [23/200], loss:568.2162\n",
            "epoch [24/200], loss:545.1955\n",
            "epoch [25/200], loss:522.9509\n",
            "epoch [26/200], loss:500.6090\n",
            "epoch [27/200], loss:478.4751\n",
            "epoch [28/200], loss:457.0525\n",
            "epoch [29/200], loss:436.1778\n",
            "epoch [30/200], loss:417.0303\n",
            "epoch [31/200], loss:399.0587\n",
            "epoch [32/200], loss:383.3534\n",
            "epoch [33/200], loss:369.3877\n",
            "epoch [34/200], loss:356.9383\n",
            "epoch [35/200], loss:345.7231\n",
            "epoch [36/200], loss:335.6319\n",
            "epoch [37/200], loss:326.4042\n",
            "epoch [38/200], loss:318.1080\n",
            "epoch [39/200], loss:310.5609\n",
            "epoch [40/200], loss:303.6494\n",
            "epoch [41/200], loss:297.4587\n",
            "epoch [42/200], loss:291.7577\n",
            "epoch [43/200], loss:286.7380\n",
            "epoch [44/200], loss:282.0600\n",
            "epoch [45/200], loss:277.9649\n",
            "epoch [46/200], loss:274.1394\n",
            "epoch [47/200], loss:270.7302\n",
            "epoch [48/200], loss:267.6820\n",
            "epoch [49/200], loss:264.8752\n",
            "epoch [50/200], loss:262.2786\n",
            "epoch [51/200], loss:259.9113\n",
            "epoch [52/200], loss:257.7568\n",
            "epoch [53/200], loss:255.8301\n",
            "epoch [54/200], loss:253.9635\n",
            "epoch [55/200], loss:252.3438\n",
            "epoch [56/200], loss:250.7283\n",
            "epoch [57/200], loss:249.2010\n",
            "epoch [58/200], loss:247.8317\n",
            "epoch [59/200], loss:246.5517\n",
            "epoch [60/200], loss:245.4509\n",
            "epoch [61/200], loss:244.3012\n",
            "epoch [62/200], loss:243.3077\n",
            "epoch [63/200], loss:242.2756\n",
            "epoch [64/200], loss:241.4209\n",
            "epoch [65/200], loss:240.5371\n",
            "epoch [66/200], loss:239.7343\n",
            "epoch [67/200], loss:239.0063\n",
            "epoch [68/200], loss:238.2493\n",
            "epoch [69/200], loss:237.6149\n",
            "epoch [70/200], loss:237.0408\n",
            "epoch [71/200], loss:236.3323\n",
            "epoch [72/200], loss:235.7672\n",
            "epoch [73/200], loss:235.0607\n",
            "epoch [74/200], loss:234.5347\n",
            "epoch [75/200], loss:233.9199\n",
            "epoch [76/200], loss:233.3153\n",
            "epoch [77/200], loss:232.8094\n",
            "epoch [78/200], loss:232.3335\n",
            "epoch [79/200], loss:231.8594\n",
            "epoch [80/200], loss:231.4061\n",
            "epoch [81/200], loss:230.9152\n",
            "epoch [82/200], loss:230.5527\n",
            "epoch [83/200], loss:230.0835\n",
            "epoch [84/200], loss:229.6167\n",
            "epoch [85/200], loss:229.1427\n",
            "epoch [86/200], loss:228.7265\n",
            "epoch [87/200], loss:228.3682\n",
            "epoch [88/200], loss:228.0353\n",
            "epoch [89/200], loss:227.5714\n",
            "epoch [90/200], loss:227.3470\n",
            "epoch [91/200], loss:227.0072\n",
            "epoch [92/200], loss:226.6297\n",
            "epoch [93/200], loss:226.3806\n",
            "epoch [94/200], loss:226.2357\n",
            "epoch [95/200], loss:225.8977\n",
            "epoch [96/200], loss:225.7252\n",
            "epoch [97/200], loss:225.4827\n",
            "epoch [98/200], loss:225.3171\n",
            "epoch [99/200], loss:225.2131\n",
            "epoch [100/200], loss:225.0200\n",
            "epoch [101/200], loss:224.7224\n",
            "epoch [102/200], loss:224.7510\n",
            "epoch [103/200], loss:224.5581\n",
            "epoch [104/200], loss:224.3199\n",
            "epoch [105/200], loss:224.2124\n",
            "epoch [106/200], loss:224.0875\n",
            "epoch [107/200], loss:224.0372\n",
            "epoch [108/200], loss:223.8694\n",
            "epoch [109/200], loss:223.7207\n",
            "epoch [110/200], loss:223.8551\n",
            "epoch [111/200], loss:223.5650\n",
            "epoch [112/200], loss:223.5316\n",
            "epoch [113/200], loss:223.6724\n",
            "epoch [114/200], loss:223.4816\n",
            "epoch [115/200], loss:223.3925\n",
            "epoch [116/200], loss:223.2184\n",
            "epoch [117/200], loss:223.0802\n",
            "epoch [118/200], loss:223.0118\n",
            "epoch [119/200], loss:222.9327\n",
            "epoch [120/200], loss:222.8506\n",
            "epoch [121/200], loss:222.7717\n",
            "epoch [122/200], loss:222.7561\n",
            "epoch [123/200], loss:222.7094\n",
            "epoch [124/200], loss:222.6231\n",
            "epoch [125/200], loss:222.5544\n",
            "epoch [126/200], loss:222.5219\n",
            "epoch [127/200], loss:222.4728\n",
            "epoch [128/200], loss:222.4265\n",
            "epoch [129/200], loss:222.3631\n",
            "epoch [130/200], loss:222.2751\n",
            "epoch [131/200], loss:222.3064\n",
            "epoch [132/200], loss:222.1615\n",
            "epoch [133/200], loss:222.1631\n",
            "epoch [134/200], loss:222.0535\n",
            "epoch [135/200], loss:222.0549\n",
            "epoch [136/200], loss:222.0433\n",
            "epoch [137/200], loss:222.0680\n",
            "epoch [138/200], loss:221.8871\n",
            "epoch [139/200], loss:221.8180\n",
            "epoch [140/200], loss:221.7711\n",
            "epoch [141/200], loss:222.1092\n",
            "epoch [142/200], loss:221.7974\n",
            "epoch [143/200], loss:221.8411\n",
            "epoch [144/200], loss:221.6238\n",
            "epoch [145/200], loss:221.6012\n",
            "epoch [146/200], loss:221.5079\n",
            "epoch [147/200], loss:221.5093\n",
            "epoch [148/200], loss:221.5684\n",
            "epoch [149/200], loss:221.4943\n",
            "epoch [150/200], loss:221.3981\n",
            "epoch [151/200], loss:221.3350\n",
            "epoch [152/200], loss:221.3511\n",
            "epoch [153/200], loss:221.2976\n",
            "epoch [154/200], loss:221.3350\n",
            "epoch [155/200], loss:221.2642\n",
            "epoch [156/200], loss:221.2606\n",
            "epoch [157/200], loss:221.1638\n",
            "epoch [158/200], loss:221.2087\n",
            "epoch [159/200], loss:221.1515\n",
            "epoch [160/200], loss:221.1596\n",
            "epoch [161/200], loss:220.9745\n",
            "epoch [162/200], loss:221.3613\n",
            "epoch [163/200], loss:221.1386\n",
            "epoch [164/200], loss:220.8220\n",
            "epoch [165/200], loss:220.9552\n",
            "epoch [166/200], loss:220.8236\n",
            "epoch [167/200], loss:220.8294\n",
            "epoch [168/200], loss:220.7722\n",
            "epoch [169/200], loss:220.7911\n",
            "epoch [170/200], loss:220.7352\n",
            "epoch [171/200], loss:220.6986\n",
            "epoch [172/200], loss:220.7437\n",
            "epoch [173/200], loss:220.6464\n",
            "epoch [174/200], loss:220.6409\n",
            "epoch [175/200], loss:220.7808\n",
            "epoch [176/200], loss:220.8529\n",
            "epoch [177/200], loss:220.6362\n",
            "epoch [178/200], loss:220.4760\n",
            "epoch [179/200], loss:220.4679\n",
            "epoch [180/200], loss:220.4494\n",
            "epoch [181/200], loss:220.4083\n",
            "epoch [182/200], loss:220.4989\n",
            "epoch [183/200], loss:220.5825\n",
            "epoch [184/200], loss:220.4427\n",
            "epoch [185/200], loss:220.3892\n",
            "epoch [186/200], loss:220.3770\n",
            "epoch [187/200], loss:220.2307\n",
            "epoch [188/200], loss:220.2646\n",
            "epoch [189/200], loss:220.4079\n",
            "epoch [190/200], loss:220.5002\n",
            "epoch [191/200], loss:220.2216\n",
            "epoch [192/200], loss:220.1329\n",
            "epoch [193/200], loss:220.1976\n",
            "epoch [194/200], loss:220.0672\n",
            "epoch [195/200], loss:220.1136\n",
            "epoch [196/200], loss:220.0661\n",
            "epoch [197/200], loss:220.1227\n",
            "epoch [198/200], loss:219.9670\n",
            "epoch [199/200], loss:220.0021\n",
            "epoch [200/200], loss:219.9300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iR93zNZH_5S",
        "outputId": "d21d25e9-eba2-4786-b52e-ac8d312482ff"
      },
      "source": [
        "# test network\n",
        "init_state = mx.nd.array([df.sample(n=1).values])\n",
        "print(init_state)\n",
        "encoding = model.encode(init_state)\n",
        "print(encoding)\n",
        "decoding = model.decode(encoding)\n",
        "print(decoding)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[[[-83.        56.       -66.666664  52.77778 ]]]\n",
            "<NDArray 1x1x4 @cpu(0)>\n",
            "\n",
            "[[-292.2518  -112.65791]]\n",
            "<NDArray 1x2 @cpu(0)>\n",
            "\n",
            "[[-72.667114  76.38964  -67.664246  26.410967]]\n",
            "<NDArray 1x4 @cpu(0)>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}